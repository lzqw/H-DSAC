use_gpu: True
enable_cuda: True 
obs_dim: 450
action_dim: 2
value_hidden_sizes: [256,256,256]           
value_hidden_activation: "gelu"
value_output_activation: "linear"
value_min_log_std: -8
value_max_log_std: 8
policy_hidden_sizes: [256,256,256]
policy_hidden_activation: "gelu"
policy_output_activation: "linear"
value_func_type: "MLP"
value_func_name: "ActionValueDistri"
policy_act_distribution: "TanhGaussDistribution"
policy_func_type: "MLP"
policy_func_name: "StochaPolicy"
log_save_interval: 10
load_buffer: False
load_human_buffer: False
discard_reward: False
policy_min_log_std: -5
policy_max_log_std: 1
auto_alpha: True
value_learning_rate: 0.0005
policy_learning_rate: 0.0005
alpha_learning_rate: 0.005
policy_update_time: 1
gamma: 0.99
tau: 0.005
delay_update: 2
TD_bound: 1
bound: 1
max_iteration: 100000
buffer_warm_size: 2000
buffer_max_size: 80000
replay_batch_size: 512
update_interval: 5
sample_batch_size: 10
apprfunc_save_interval: 1000
takeover_stop_td: False
save_buffer: True
save_buffer_fre: 50000
buffer_path: ""
human_buffer_path: ""
warm_up: False
q_bound: 1
warm_up_step: 80000
